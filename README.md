# controllable-text-generation-review
A review project for the research areas of controllable text generation under natural language processing. The project provides a thorough way of categorization for CTG with 50+ most recent research papers with detailed summarization, evaluation, comparison with their techniques and models. The catgetories include Variational Auto-Encoder(VAE), Recurrent Neural Network(RNN), Pre-trained Language Model(PLM), Attention and Transformer, Fine-tuning, and Training Objectives. The schema is shown below:



